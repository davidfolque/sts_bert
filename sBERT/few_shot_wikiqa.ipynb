{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Only needed in pycharm\n",
    "import os\n",
    "\n",
    "os.chdir('/home/cs-folq1/src/sts_bert/sBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_qa (/home/cs-folq1/.cache/huggingface/datasets/wiki_qa/default/0.1.0/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from Datasets import load_wiki_qa\n",
    "from WikiQA.WikiQAClassifierTrainer import WikiQAClassifierTrainer\n",
    "from WikiQA.WikiQABinaryClassifierTrainer import WikiQABinaryClassifierTrainer\n",
    "from CrossEncoder import CrossEncoder\n",
    "\n",
    "wiki_qa = load_wiki_qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sts_cross_model_path = \\\n",
    "    'results/pretraining_sts/results_210702_094435_cross-encoder_cls-pooling-hidden_best_model.bin'\n",
    "original_nli_sts_cross_model_path = \\\n",
    "    'results/pretraining_sts/results_210702_094435_cross-encoder_nli-base_best_model.bin'\n",
    "original_sts_bi_model_path = \\\n",
    "    'results/pretraining_sts/results_210707_152607_bi-encoder_base-cls-pooling_best_model.bin'\n",
    "original_nli_sts_bi_model_path = \\\n",
    "    'results/pretraining_sts/results_210707_152607_bi-encoder_nli-cls-pooling_best_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on PAWS.\n",
    "\n",
    "def run_experiment(config):\n",
    "    encoder, pretrained_model = config['pretrained_model'].split('/')\n",
    "\n",
    "    if encoder == 'cross':\n",
    "        if pretrained_model in ['bert', 'sts']:\n",
    "            sts_model = CrossEncoder(mode='cls-pooling-hidden')\n",
    "            if pretrained_model == 'sts':\n",
    "                print('Loading sts pretrained model from ' + original_sts_cross_model_path)\n",
    "                sts_model.load_state_dict(torch.load(original_sts_cross_model_path))\n",
    "        else:\n",
    "            assert pretrained_model in ['nli', 'nli-sts']:\n",
    "            sts_model = CrossEncoder(mode='nli-base')\n",
    "            if pretrained_model == 'nli-sts':\n",
    "                print('Loading nli and sts pretrained model from ' +\n",
    "                    original_nli_sts_cross_model_path)\n",
    "                sts_model.load_state_dict(torch.load(original_nli_sts_cross_model_path))\n",
    "        \n",
    "        if pretrained_model in ['bert', 'nli']:\n",
    "            paws_model = CrossEncoderPretrained(sts_model, mode='as-is')\n",
    "        else:\n",
    "            assert(pretrained_model in ['sts', 'nli-sts'])\n",
    "            paws_model = CrossEncoderPretrained(sts_model, mode='replace-head')\n",
    "    else:\n",
    "        assert(encoder == 'bi')\n",
    "        if pretrained_model == 'nli':\n",
    "            paws_model = BiEncoder(mode='nli-linear-pooling', head='extra-head-sub')\n",
    "        else:\n",
    "            paws_model = BiEncoder(mode='base-linear-pooling', head='extra-head-sub')\n",
    "            if pretrained_model == 'nli-sts':\n",
    "                print('Loading nli and sts pretrained model from ' + original_nli_sts_bi_model_path)\n",
    "                paws_model.load_state_dict(torch.load(original_nli_sts_bi_model_path))\n",
    "            elif pretrained_model == 'sts':\n",
    "                print('Loading sts pretrained model from ' + original_sts_bi_model_path)\n",
    "                paws_model.load_state_dict(torch.load(original_sts_bi_model_path))\n",
    "            else:\n",
    "                assert(pretrained_model == 'bert')\n",
    "\n",
    "\n",
    "    trainer = PawsTrainer(model=paws_model, train_dataset=train_dataset_subset,\n",
    "                          dataset={'dev': dev_dataset_subset, 'test': wiki_qa['test']},\n",
    "                          num_epochs=config['num_epochs'], batch_size=config['batch_size'],\n",
    "                          lr=config['lr'])\n",
    "    result = trainer.train(disable_progress_bar=False, eval_zero_shot=True)\n",
    "    save_name = 'pretrained_' + config['pretrained_model']\n",
    "    return result, paws_model, save_name\n",
    "\n",
    "\n",
    "grid = {\n",
    "    'num_epochs': 10,  # Size 5000 => 50s per epoch????\n",
    "    'batch_size': 16,\n",
    "    'lr': 2e-5,\n",
    "    'pretrained_model': [\n",
    "        'cross/bert', 'cross/nli', 'cross/sts', 'cross/nli-sts',\n",
    "        'bi/bert', 'bi/nli', 'bi/sts', 'bi/nli-sts'],\n",
    "    # 'mode': ['replace-head', 'shift-bias', 'additional-head'],\n",
    "    # 'mode': 'shift-bias',\n",
    "    # 'train_size': 2000,\n",
    "    'train_size': [10, 50, 100, 500, 1000, 2000, 5000, 10000],\n",
    "    'train_subset_seed': [1, 2, 3]\n",
    "}\n",
    "\n",
    "#grid_run = GridRun(run_experiment, results_dir='results', experiment_name='paws_from_nli_sts')\n",
    "grid_run = GridRun(run_experiment)\n",
    "grid_run.run(grid, save_best=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Question has more answers than the batch size\n",
      "Warning: Question has more answers than the batch size\n",
      "Warning: Question has more answers than the batch size\n",
      "Scheduler type: constant_with_warmup, epochs: 3, steps per epoch: 1250, total steps: 3750, warmup steps: 0\n"
     ]
    }
   ],
   "source": [
    "model = CrossEncoder(mode='mean-pooling')\n",
    "trainer = WikiQABinaryClassifierTrainer(model=model, dataset=wiki_qa, mode='all-unscaled',\n",
    "                                        trainset_size=20000, trainset_seed=1, num_epochs=3,\n",
    "                                        batch_size=16, lr=2e-5, devset_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:08<00:00, 19.03it/s]\n",
      "  0%|          | 1/1250 [00:00<02:56,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted-  Predicted+\n",
      "Gold-         690        1903\n",
      "Gold+          28         112\n",
      "Precision 0.06, recall 0.80, F1 0.10\n",
      "Epoch 0   : loss: 0.7227  , score: 0.1039  *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [03:02<00:00,  6.83it/s]\n",
      "100%|██████████| 171/171 [00:08<00:00, 19.07it/s]\n",
      "  0%|          | 1/1250 [00:00<03:21,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted-  Predicted+\n",
      "Gold-        2583          10\n",
      "Gold+         127          13\n",
      "Precision 0.57, recall 0.09, F1 0.16\n",
      "Epoch 1   : loss: 0.1475  , score: 0.1595  *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [03:03<00:00,  6.82it/s]\n",
      "100%|██████████| 171/171 [00:08<00:00, 19.07it/s]\n",
      "  0%|          | 1/1250 [00:00<02:24,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted-  Predicted+\n",
      "Gold-        2548          45\n",
      "Gold+          78          62\n",
      "Precision 0.58, recall 0.44, F1 0.50\n",
      "Epoch 2   : loss: 0.1631  , score: 0.5020  *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [03:01<00:00,  6.88it/s]\n",
      "100%|██████████| 171/171 [00:08<00:00, 19.33it/s]\n",
      "  1%|          | 3/386 [00:00<00:18, 20.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted-  Predicted+\n",
      "Gold-        2541          52\n",
      "Gold+          88          52\n",
      "Precision 0.50, recall 0.37, F1 0.43\n",
      "Epoch 3   : loss: 0.1704  , score: 0.4262  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [00:19<00:00, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted-  Predicted+\n",
      "Gold-        5770         102\n",
      "Gold+         198          95\n",
      "Precision 0.48, recall 0.32, F1 0.39\n",
      "Test loss: 0.1588, score: 0.3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.38775510204081637, tensor(0.1588))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(disable_progress_bar=False, eval_zero_shot=True, early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.5538e-03, 5.6121e-04, 5.7433e-02, 7.5890e-01, 1.0651e-02, 1.2402e-03,\n",
       "         1.6844e-03, 5.5506e-04, 4.8925e-04, 1.6593e-01], device='cuda:0',\n",
       "        grad_fn=<DivBackward0>),\n",
       " [(0.0, 0),\n",
       "  (0.0, 0),\n",
       "  (0.0, 0),\n",
       "  (0.0, 0),\n",
       "  (0.0, 0),\n",
       "  (0.0, 0),\n",
       "  (0.0, 0),\n",
       "  (0.0, 0),\n",
       "  (0.0, 0),\n",
       "  (0.0, 0)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict_batch({'question': [wiki_qa['validation'][i]['question'] for i in range(10)],\n",
    "                       'answer': [wiki_qa['validation'][i]['answer'] for i in range(10)],\n",
    "                       'label': [wiki_qa['validation'][i]['label'] for i in range(10)],\n",
    "                       'question_number': [0] * 10\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Headquartered in Houston , Texas , BMC develops, markets and sells software used for multiple functions, including IT service management, data center automation, performance management, virtualization lifecycle management and cloud computing management.',\n",
       "  'document_title': 'BMC Software',\n",
       "  'label': 0,\n",
       "  'question': 'how big is bmc software in houston, tx',\n",
       "  'question_id': 'Q11'},\n",
       " {'answer': 'The name \"BMC\" is taken from the surnames of its three founders—Scott Boulette, John Moores, and Dan Cloer.',\n",
       "  'document_title': 'BMC Software',\n",
       "  'label': 0,\n",
       "  'question': 'how big is bmc software in houston, tx',\n",
       "  'question_id': 'Q11'},\n",
       " {'answer': 'Employing over 6,000, BMC is often credited with pioneering the BSM concept as a way to help better align IT operations with business needs.',\n",
       "  'document_title': 'BMC Software',\n",
       "  'label': 1,\n",
       "  'question': 'how big is bmc software in houston, tx',\n",
       "  'question_id': 'Q11'},\n",
       " {'answer': 'For 2011, the company recorded an annual revenue of $2.1 billion, making it the #20 largest software company in terms of revenue for that year.',\n",
       "  'document_title': 'BMC Software',\n",
       "  'label': 1,\n",
       "  'question': 'how big is bmc software in houston, tx',\n",
       "  'question_id': 'Q11'},\n",
       " {'answer': 'I Love Lucy is an American television sitcom starring Lucille Ball , Desi Arnaz , Vivian Vance , and William Frawley .',\n",
       "  'document_title': 'I Love Lucy',\n",
       "  'label': 0,\n",
       "  'question': 'how long was i love lucy on the air',\n",
       "  'question_id': 'Q48'},\n",
       " {'answer': 'The black-and-white series originally ran from October 15, 1951, to May 6, 1957, on the Columbia Broadcasting System (CBS).',\n",
       "  'document_title': 'I Love Lucy',\n",
       "  'label': 1,\n",
       "  'question': 'how long was i love lucy on the air',\n",
       "  'question_id': 'Q48'},\n",
       " {'answer': 'After the series ended in 1957, however, a modified version continued for three more seasons with 13 one-hour specials, running from 1957 to 1960, known first as The Lucille Ball-Desi Arnaz Show and later in reruns as The Lucy–Desi Comedy Hour .',\n",
       "  'document_title': 'I Love Lucy',\n",
       "  'label': 0,\n",
       "  'question': 'how long was i love lucy on the air',\n",
       "  'question_id': 'Q48'},\n",
       " {'answer': 'I Love Lucy was the most watched show in the United States in four of its six seasons, and was the first to end its run at the top of the Nielsen ratings (an accomplishment later matched by The Andy Griffith Show and Seinfeld ).',\n",
       "  'document_title': 'I Love Lucy',\n",
       "  'label': 0,\n",
       "  'question': 'how long was i love lucy on the air',\n",
       "  'question_id': 'Q48'},\n",
       " {'answer': 'I Love Lucy is still syndicated in dozens of languages across the world.',\n",
       "  'document_title': 'I Love Lucy',\n",
       "  'label': 0,\n",
       "  'question': 'how long was i love lucy on the air',\n",
       "  'question_id': 'Q48'},\n",
       " {'answer': 'The show was the first scripted television program to be shot on 35 mm film in front of a studio audience, and won five Emmy Awards and received numerous nominations.',\n",
       "  'document_title': 'I Love Lucy',\n",
       "  'label': 0,\n",
       "  'question': 'how long was i love lucy on the air',\n",
       "  'question_id': 'Q48'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wiki_qa['validation'][i] for i in range(10, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#dev_pred = trainer.predict(trainer.dev_dl)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(np.array(dev_pred[1])[:,0], np.array(dev_pred[0]) > 0.5)\n",
    "#dev_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted-  Predicted+\n",
      "Gold-        1760         833\n",
      "Gold+          84          56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.DataFrame(cm, columns=['Predicted-', 'Predicted+'], index=['Gold-', 'Gold+']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'best_dev_performance',\n",
       " 'best_model',\n",
       " 'best_model_epoch',\n",
       " 'debug_step_function',\n",
       " 'dev_dl',\n",
       " 'loss_function',\n",
       " 'lr_scheduler',\n",
       " 'model',\n",
       " 'num_epochs',\n",
       " 'optimizer',\n",
       " 'performance',\n",
       " 'predict',\n",
       " 'predict_batch',\n",
       " 'score',\n",
       " 'sigmoid',\n",
       " 'test_dl',\n",
       " 'train',\n",
       " 'train_dl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}